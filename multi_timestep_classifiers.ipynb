{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow\n",
    "from keras import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    TimeDistributed,\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv1D,\n",
    "    Flatten, \n",
    "    Embedding,\n",
    "    Dropout, \n",
    "    Bidirectional)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy\n",
    "from numba import cuda \n",
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "%run constants.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Output window override (so you can predict on more ouput windows)\n",
    "TIME_STEP: int = 90\n",
    "output: int = 60\n",
    "\n",
    "# Some file name editing for timestep\n",
    "f = os.path.basename(X_TRAIN_SINGLE_TIMESTEP_RAW)\n",
    "X_TRAIN_SINGLE_TIMESTEP_RAW = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(X_TEST_SINGLE_TIMESTEP_RAW)\n",
    "X_TEST_SINGLE_TIMESTEP_RAW = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(X_VAL_SINGLE_TIMESTEP_RAW)\n",
    "X_VAL_SINGLE_TIMESTEP_RAW = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "\n",
    "\n",
    "f = os.path.basename(X_TRAIN_INPUT_SAVE_FILE_VEC_SINGLE_TIMESTEP)\n",
    "X_TRAIN_INPUT_SAVE_FILE_VEC_SINGLE_TIMESTEP = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(X_TEST_INPUT_SAVE_FILE_VEC_SINGLE_TIMESTEP)\n",
    "X_TEST_INPUT_SAVE_FILE_VEC_SINGLE_TIMESTEP = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(X_VAL_INPUT_SAVE_FILE_VEC_SINGLE_TIMESTEP)\n",
    "X_VAL_INPUT_SAVE_FILE_VEC_SINGLE_TIMESTEP = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "\n",
    "f = os.path.basename(X_TRAIN_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP)\n",
    "X_TRAIN_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(X_TEST_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP)\n",
    "X_TEST_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(X_VAL_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP)\n",
    "X_VAL_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "\n",
    "f = os.path.basename(Y_TRAIN_INPUT_SAVE_FILE)\n",
    "Y_TRAIN_INPUT_SAVE_FILE = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(output) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(Y_TEST_INPUT_SAVE_FILE)\n",
    "Y_TEST_INPUT_SAVE_FILE = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(output) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(Y_VAL_INPUT_SAVE_FILE)\n",
    "Y_VAL_INPUT_SAVE_FILE = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(output) + os.path.splitext(os.path.basename(f))[1]) \n",
    "\n",
    "f = os.path.basename(EMBEDDING_MATRIX_SAVE_FILE)\n",
    "EMBEDDING_MATRIX_SAVE_FILE= os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(VOCAB_SAVE_FILE)\n",
    "VOCAB_SAVE_FILE = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "f = os.path.basename(TRAIN_CORPORA)\n",
    "TRAIN_CORPORA = os.path.join(DATA_DIR, os.path.splitext(os.path.basename(f))[0] + \"_\" + str(TIME_STEP) + os.path.splitext(os.path.basename(f))[1]) \n",
    "\n",
    "file_suffix: str = f'_i{TIME_STEP}_o{output}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Saving varaibles for reuse ------\n",
      "X_train shape: (2465, 90, 200)\n",
      "Y_train shape: (2465,)\n",
      "X_test shape: (685, 90, 200)\n",
      "Y_test shape: (685,)\n",
      "X_val shape: (274, 90, 200)\n",
      "Y_val shape: (274,)\n",
      "Embedding shape: (10000, 100)\n",
      "Total 0 values: 1151\n",
      "Total 1 values: 1314\n"
     ]
    }
   ],
   "source": [
    "with open(X_TRAIN_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP, \"rb\") as f:\n",
    "        x_train = pickle.load(f)\n",
    "with open(Y_TRAIN_INPUT_SAVE_FILE, \"rb\") as f:\n",
    "        y_train = pickle.load(f)\n",
    "with open(X_TEST_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP, \"rb\") as f:\n",
    "        x_test = pickle.load(f)\n",
    "with open(Y_TEST_INPUT_SAVE_FILE, \"rb\") as f:\n",
    "        y_test = pickle.load(f)\n",
    "with open(X_VAL_INPUT_SAVE_FILE_VEC_MULTI_TIMESTEP, \"rb\") as f:\n",
    "        x_val = pickle.load(f)\n",
    "with open(Y_VAL_INPUT_SAVE_FILE, \"rb\") as f:\n",
    "        y_val = pickle.load(f)\n",
    "with open(EMBEDDING_MATRIX_SAVE_FILE, \"rb\") as f:\n",
    "        embedding_matrix = pickle.load(f)\n",
    "\n",
    "print(\"------Saving varaibles for reuse ------\")\n",
    "print(f\"X_train shape: {x_train.shape}\")\n",
    "print(f\"Y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {x_test.shape}\")\n",
    "print(f\"Y_test shape: {y_test.shape}\")\n",
    "print(f\"X_val shape: {x_val.shape}\")\n",
    "print(f\"Y_val shape: {y_val.shape}\")\n",
    "print(f\"Embedding shape: {embedding_matrix.shape}\")\n",
    "print(f\"Total 0 values: {(y_train == 0).sum()}\")\n",
    "print(f\"Total 1 values: {(y_train == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2465, 18000)\n",
      "After OverSampling, the shape of train_X: (2628, 18000)\n",
      "After OverSampling, the shape of train_y: (2628,)\n",
      "After OverSampling, counts of label '1': 1314\n",
      "After OverSampling, counts of label '0': 1314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2628, 90, 200)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if BALANCE_DATA:\n",
    "    arr = x_train.reshape(len(x_train), -1)\n",
    "    print(arr.shape)\n",
    "    sm = SMOTE(random_state=SEED)\n",
    "    x_train_bal, y_train = sm.fit_resample(arr, y_train.ravel())\n",
    "    print(f\"After OverSampling, the shape of train_X: {x_train_bal.shape}\")\n",
    "    print(f\"After OverSampling, the shape of train_y: {y_train.shape}\")\n",
    "    print(f\"After OverSampling, counts of label '1': {sum(y_train == 1)}\")\n",
    "    print(f\"After OverSampling, counts of label '0': {sum(y_train == 0)}\")\n",
    "    x_train = numpy.reshape(x_train_bal, (-1, x_train.shape[1], x_train.shape[2]))\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_layer = Embedding(\n",
    "#         MAX_VOCAB_SIZE,\n",
    "#         EMBEDDING_DIM,\n",
    "#         weights=[embedding_matrix],\n",
    "#         input_length=MAX_SEQUENCE_LENGTH,\n",
    "#         trainable=False,)\n",
    "\n",
    "# x_train= tensorflow.convert_to_tensor(x_train)\n",
    "# y_train= tensorflow.convert_to_tensor(y_train)\n",
    "\n",
    "# optimizer = tensorflow.keras.optimizers.Adam(learning_rate=LR)\n",
    "# loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def plot_graph(history):\n",
    "#     history_dict = history.history\n",
    "#     print(history_dict.keys())\n",
    "\n",
    "#     acc = history_dict['binary_accuracy']\n",
    "#     val_acc = history_dict['val_binary_accuracy']\n",
    "#     loss = history_dict['loss']\n",
    "#     val_loss = history_dict['val_loss']\n",
    "\n",
    "#     epochs = range(1, len(acc) + 1)\n",
    "#     fig = plt.figure(figsize=(10, 6))\n",
    "#     fig.tight_layout()\n",
    "\n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     # r is for \"solid red line\"\n",
    "#     plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "#     # b is for \"solid blue line\"\n",
    "#     plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#     plt.title('Training and validation loss')\n",
    "#     # plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "#     plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKED LSTM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_stacked_lstm():\n",
    "#     document_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int64\")\n",
    "#     embedding_sequences =embedding_layer(document_input)\n",
    "#     x = LSTM(TIME_STEP, return_sequences=True)(embedding_sequences)\n",
    "#     x = LSTM(TIME_STEP)(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     doc_model = Model(document_input, x)\n",
    "#     input_docs = Input(\n",
    "#                 shape=(TIME_STEP, MAX_SEQUENCE_LENGTH), name=\"input_docs\", dtype=\"int32\"\n",
    "#             )\n",
    "\n",
    "#     x = TimeDistributed(doc_model, name=\"token_embedding_model\")(input_docs)\n",
    "#     x = LSTM(TIME_STEP)(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model(input_docs, outputs)\n",
    "\n",
    "#     model.summary()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run_stacked_lstm()\n",
    "# model.compile(optimizer=optimizer,\n",
    "#                          loss=loss,\n",
    "#                          metrics=metrics)\n",
    "# history = model.fit(x=x_train, y=y_train,\n",
    "#                                 validation_data = (x_val, y_val),\n",
    "#                                epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x= x_test, y= y_test)\n",
    "# print(f'Loss: {loss}')\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# graph = plot_graph(history)\n",
    "# save_file_name: str = f'saved_graphs/multi_timestep_lstm_stacked{file_suffix}.png' \n",
    "# graph.savefig(save_file_name)\n",
    "# model_name: str = f'saved_model/multi_timestep_lstm_stacked{file_suffix}' \n",
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_lstm():\n",
    "#     document_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "#     embedding_sequences =embedding_layer(document_input)\n",
    "#     x = LSTM(TIME_STEP)(embedding_sequences)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     doc_model = Model(document_input, x)\n",
    "#     input_docs = Input(\n",
    "#                 shape=(TIME_STEP, MAX_SEQUENCE_LENGTH), name=\"input_docs\", dtype=\"int32\"\n",
    "#             )\n",
    "\n",
    "#     x = TimeDistributed(doc_model, name=\"token_embedding_model\")(input_docs)\n",
    "#     x = LSTM(TIME_STEP)(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model(input_docs, outputs)\n",
    "#     model.summary()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run_lstm()\n",
    "\n",
    "# optimizer = tensorflow.keras.optimizers.Adam(learning_rate=LR)\n",
    "# loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# metrics = tf.metrics.BinaryAccuracy()\n",
    "# model.compile(optimizer=optimizer,\n",
    "#                          loss=loss,\n",
    "#                          metrics=metrics)\n",
    "# history = model.fit(x=x_train, y=y_train,\n",
    "#                                 validation_data = (x_val, y_val),\n",
    "#                                epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x= x_test, y= y_test)\n",
    "# print(f'Loss: {loss}')\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# graph = plot_graph(history)\n",
    "# save_file_name: str = f'saved_graphs/multi_timestep_lstm{file_suffix}.png' \n",
    "# graph.savefig(save_file_name)\n",
    "# model_name: str = f'saved_model/multi_timestep_lstm{file_suffix}' \n",
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_cnn():\n",
    "#     document_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "#     embedding_sequences = embedding_layer(document_input)\n",
    "\n",
    "#     x = Conv1D(filters=400, kernel_size=5, padding=\"valid\")(embedding_sequences)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     doc_model = Model(document_input, x)\n",
    "\n",
    "#     input_docs = Input(\n",
    "#             shape=(TIME_STEP, MAX_SEQUENCE_LENGTH), name=\"input_docs\", dtype=\"int32\"\n",
    "#         )\n",
    "\n",
    "#     x = TimeDistributed(doc_model, name=\"token_embedding_model\")(input_docs)\n",
    "#     x = Conv1D(filters=400, kernel_size=5, padding=\"valid\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Flatten()(x)\n",
    "#     outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "#     model = Model(input_docs, outputs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run_cnn()\n",
    "\n",
    "# optimizer = tensorflow.keras.optimizers.Adam(learning_rate=LR)\n",
    "# loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# metrics = tf.metrics.BinaryAccuracy()\n",
    "# model.compile(optimizer=optimizer,\n",
    "#                          loss=loss,\n",
    "#                          metrics=metrics)\n",
    "# history = model.fit(x=x_train, y=y_train,\n",
    "#                                 validation_data = (x_val, y_val),\n",
    "#                                epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x= x_test, y= y_test)\n",
    "# print(f'Loss: {loss}')\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# graph = plot_graph(history)\n",
    "# save_file_name: str = f'saved_graphs/multi_timestep_cnn{file_suffix}.png' \n",
    "# graph.savefig(save_file_name)\n",
    "# model_name: str = f'saved_model/multi_timestep_cnn{file_suffix}' \n",
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_bilstm():\n",
    "#     document_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "#     embedding_sequences =embedding_layer(document_input)\n",
    "#     x = Bidirectional(LSTM(TIME_STEP))(embedding_sequences)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     doc_model = Model(document_input, x)\n",
    "#     input_docs = Input(\n",
    "#                 shape=(TIME_STEP, MAX_SEQUENCE_LENGTH), name=\"input_docs\", dtype=\"int32\"\n",
    "#             )\n",
    "\n",
    "#     x = TimeDistributed(doc_model, name=\"token_embedding_model\")(input_docs)\n",
    "#     x = Bidirectional(LSTM(TIME_STEP))(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model(input_docs, outputs)\n",
    "#     model.summary()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run_bilstm()\n",
    "\n",
    "# optimizer = tensorflow.keras.optimizers.Adam(learning_rate=LR)\n",
    "# loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# metrics = tf.metrics.BinaryAccuracy()\n",
    "# model.compile(optimizer=optimizer,\n",
    "#                          loss=loss,\n",
    "#                          metrics=metrics)\n",
    "# history = model.fit(x=x_train, y=y_train,\n",
    "#                                 validation_data = (x_val, y_val),\n",
    "#                                epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x= x_test, y= y_test)\n",
    "# print(f'Loss: {loss}')\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# graph = plot_graph(history)\n",
    "# save_file_name: str = f'saved_graphs/multi_timestep_bilstm{file_suffix}.png' \n",
    "# graph.savefig(save_file_name)\n",
    "# model_name: str = f'saved_model/multi_timestep_bilstm{file_suffix}' \n",
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Stacked Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_bilstm_stacked():\n",
    "#     document_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "#     embedding_sequences =embedding_layer(document_input)\n",
    "#     x = Bidirectional(LSTM(60, return_sequences=True))(embedding_sequences)\n",
    "#     x = Bidirectional(LSTM(60))(x)\n",
    "#     doc_model = Model(document_input, x)\n",
    "#     input_docs = Input(\n",
    "#                 shape=(TIME_STEP, MAX_SEQUENCE_LENGTH), name=\"input_docs\", dtype=\"int32\"\n",
    "#             )\n",
    "\n",
    "#     x = TimeDistributed(doc_model, name=\"token_embedding_model\")(input_docs)\n",
    "#     x = Bidirectional(LSTM(60))(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model(input_docs, outputs)\n",
    "#     model.summary()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run_bilstm_stacked()\n",
    "\n",
    "# optimizer = tensorflow.keras.optimizers.Adam(learning_rate=LR)\n",
    "# loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# metrics = tf.metrics.BinaryAccuracy()\n",
    "# model.compile(optimizer=optimizer,\n",
    "#                          loss=loss,\n",
    "#                          metrics=metrics)\n",
    "# history = model.fit(x=x_train, y=y_train,\n",
    "#                                 validation_data = (x_val, y_val),\n",
    "#                                epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x= x_test, y= y_test)\n",
    "# print(f'Loss: {loss}')\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# graph = plot_graph(history)\n",
    "# save_file_name: str = f'saved_graphs/stacked_bilstm_i{TIME_STEP}_o{output}.png' \n",
    "# graph.savefig(save_file_name)\n",
    "# model_name: str = f'saved_model/bilstm_stacked_i{TIME_STEP}_o{output}' \n",
    "# model.save(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6f07f10bbd904384622e2c81da346bac6398da26490ea76cc729ffb1c8c49fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
